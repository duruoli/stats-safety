import lighteval
from lighteval.logging.evaluation_tracker import EvaluationTracker
from lighteval.models.vllm.vllm_model import VLLMModelConfig
from lighteval.pipeline import ParallelismManager, Pipeline, PipelineParameters
from lighteval.utils.utils import EnvConfig
from lighteval.utils.imports import is_accelerate_available
from datetime import timedelta


if is_accelerate_available():
    from accelerate import Accelerator, InitProcessGroupKwargs
    accelerator = Accelerator(kwargs_handlers=[InitProcessGroupKwargs(timeout=timedelta(seconds=3000))])
else:
    accelerator = None

def evaluate_model(model_name, model_id, safety_tasks):
    """Evaluate a single model on safety benchmarks"""
    evaluation_tracker = EvaluationTracker(
        output_dir=f"./results_{model_id}",
        save_details=True,
        push_to_hub=True,
        hub_results_org="Duruo",
    )

    pipeline_params = PipelineParameters(
        launcher_type=ParallelismManager.ACCELERATE,
        env_config=EnvConfig(cache_dir="tmp/"),
        override_batch_size=1,
        # Increase this for full evaluation
        max_samples=10
    )

    model_config = VLLMModelConfig(
        pretrained=model_name,
        dtype="float16",
        use_chat_template=True,
    )

    pipeline = Pipeline(
        tasks=safety_tasks,
        pipeline_parameters=pipeline_params,
        evaluation_tracker=evaluation_tracker,
        model_config=model_config,
        #custom_task_directory=None,
    )

    pipeline.evaluate()
    pipeline.save_and_push_results()
    pipeline.show_results()
    
    return pipeline

def main():
    # Select safety benchmarks
    # Examples: "bbq|truthfulqa|ethics|helm_truthful_qa|harmbench"
    safety_tasks = "bbq|truthfulqa|ethics" 
    
    # 1. Evaluate the pre-trained model
    pretrained_results = evaluate_model(
        "google/gemma-3-1b-it",  # Original pre-trained model
        "pretrained",
        safety_tasks
    )
    
    # 2. Evaluate your fine-tuned model
    finetuned_results = evaluate_model(
        "Duruo/gemma-3-finetune",  # Your fine-tuned model on HF
        "finetuned",
        safety_tasks
    )
    
    # You could add code here to compare results between the two models

if __name__ == "__main__":
    main()